{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a fit of the data with the Verhulst Model and store the outcome\n",
    "\n",
    "### Just the run the notebook and then switch to COVID_Italy_Plot to look at the data and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "import datetime\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source: Protezione civile, official Italian goverment press release\n",
    "\n",
    "### http://www.protezionecivile.gov.it/web/guest/media-comunicazione/comunicati-stampa\n",
    "\n",
    "### CSV File available on GitHub\n",
    "https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-andamento-nazionale/dpc-covid19-ita-andamento-nazionale.\n",
    "\n",
    "### Infographics from Italian Government\n",
    "http://opendatadpc.maps.arcgis.com/apps/opsdashboard/index.html#/b0c68bce2cce478eaac82fe38d4138b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Load data and define some needed parameters, as the total population\n",
    "N_ita = 60.48*np.power(10,6)\n",
    "\n",
    "#Load the regional data into a Pandas DataFrame.\n",
    "url = 'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
    "covid19_ita_full = pd.read_csv(url)\n",
    "\n",
    "#Load the National data into another Pandas DataFrame\n",
    "url_national = 'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-andamento-nazionale/dpc-covid19-ita-andamento-nazionale.csv'\n",
    "covid19_ita_nazionale = pd.read_csv(url_national)\n",
    "\n",
    "#We are loading the national data as if they were part of a region called \"Italia\" with code 0\n",
    "#to have the ability to easily plot the national data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Filter and adjust the pandas dataframe so that the national data conform with the regional database\n",
    "\n",
    "#New columns \n",
    "covid19_ita_nazionale['codice_regione'] = [0]*covid19_ita_nazionale.shape[0]\n",
    "covid19_ita_nazionale['denominazione_regione'] = ['Italia']*covid19_ita_nazionale.shape[0]\n",
    "covid19_ita_nazionale['lat'] = [0]*covid19_ita_nazionale.shape[0]\n",
    "covid19_ita_nazionale['long'] = [0]*covid19_ita_nazionale.shape[0]\n",
    "# Reorder the columns\n",
    "covid19_ita_nazionale = covid19_ita_nazionale[list(covid19_ita_full.columns)]\n",
    "\n",
    "#Append the national data to the regional database\n",
    "covid19_ita = covid19_ita_full.append(covid19_ita_nazionale, ignore_index=True)\n",
    "\n",
    "#Convert the string into a datetime object to keep track of time\n",
    "covid19_ita['data']=pd.to_datetime(covid19_ita['data'],format=\"%Y-%m-%d %H:%M:%S\") \n",
    "#covid19_ita.dtypes\n",
    "\n",
    "#Retain only interesting data and rename columns\n",
    "covid19_ita=covid19_ita.drop(columns=['stato', 'lat','long'])\n",
    "\n",
    "#Translate header in English\n",
    "covid19_ita.columns = ['date', 'code_region', 'region', 'checked_in','intensive_care','total_admitted','home_isolation','currently_positive','new_positives','recovered','deceased','total_cases','swabs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Define the function to use for curve_fit. Here we are using the Verhulst model\n",
    "def Verhulst(t, K, I0, r):\n",
    "    return (K*I0*np.exp(r*t))/(K+I0*(np.exp(r*t)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to create the numpy array of times associated to the data. The time-scale is in days\n",
    "def time_vector(data_frame):\n",
    "    time_frame = data_frame[data_frame.region=='Italia']['date'].to_numpy()\n",
    "    t_vec = np.zeros(len(time_frame))\n",
    "    for k in range(len(time_frame)):\n",
    "        t_vec[k] = ((time_frame[k]-time_frame[0]).item())/(np.power(10,9)*60*60*24)\n",
    "    return t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to fit the data\n",
    "def data_analysis_single(region,indicator_to_plot):\n",
    "    time_Data = time_vector(covid19_ita)\n",
    "    y_Data = covid19_ita[covid19_ita.region==region][indicator_to_plot].to_numpy()\n",
    "    fittedParameters, covariance = curve_fit(Verhulst,time_Data,y_Data, bounds=([0,0,0],[600000,1000,1]))\n",
    "    return fittedParameters, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Full list of regions and indicators to analyze\n",
    "region_list = covid19_ita[0:21].region.to_list()\n",
    "region_list.append('Italia')\n",
    "indicators = list(covid19_ita.columns.values)[3:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit with a Verhulst model and fill a csv with the value of the parameters and their error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Fixed Region Fit\n",
    "for k in region_list:\n",
    "    with open('./Fit_Data/Regions/Verhulst_Parameters_{}.csv'.format(k), 'w', newline='') as f:\n",
    "        thewriter = csv.writer(f)\n",
    "        thewriter.writerow(['indicator','K','delta_K','r','delta_r','I0','delta_I0'])\n",
    "        for n in indicators:\n",
    "            p_opt, p_cov = data_analysis_single(k,n)\n",
    "            p_err = np.sqrt(p_cov.diagonal())\n",
    "            thewriter.writerow([n,p_opt[0],p_err[0],p_opt[2],p_err[2],p_opt[1],p_err[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Fixed Indicator Fit\n",
    "for n in indicators:\n",
    "    with open('./Fit_Data/Indicators/Verhulst_Parameters_{}.csv'.format(n), 'w', newline='') as f:\n",
    "        thewriter = csv.writer(f)\n",
    "        thewriter.writerow(['region','K','delta_K','r','delta_r','I0','delta_I0'])\n",
    "        for k in region_list:\n",
    "            p_opt, p_cov = data_analysis_single(k,n)\n",
    "            p_err = np.sqrt(p_cov.diagonal())\n",
    "            thewriter.writerow([k,p_opt[0],p_err[0],p_opt[2],p_err[2],p_opt[1],p_err[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
